# Advanced reinforcement learning
### Zach Cohen and John Vastola

This session is on 'advanced' reinforcement learning (RL). In particular, given some challenging real-world task, what ingredients should we think about including in a RL model to make it (i) effective and (ii) stable?

We will focus on trying to understand the actor-critic architecture, and a specific algorithmic instantiation of it called Advantage Actor Critic (A2C). We will also touch on a few other RL model features that help with more challenging/realistic tasks.

Familiarity with RL, or with previous ML from scratch sessions, is not assumed. However, the two previous sessions on RL:

[1. Basic RL](https://github.com/DrugowitschLab/ML-from-scratch-seminar/tree/master/reinforcement%20learning)

[2. Deep RL](https://github.com/DrugowitschLab/ML-from-scratch-seminar/tree/master/DeepRL)

may be helpful if you're having trouble with the basic concepts.

**Links to notebooks**:

Day 1: https://colab.research.google.com/drive/1SLgoxl3DfXQXe0Tlhs1w_3DnUXpN4vsS

Day 2: https://colab.research.google.com/drive/1mpSDutsbras-BF9RDebUTQK4leBzEkrV?usp=sharing
