{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "import autograd.numpy.random as npr\n",
    "from autograd.numpy.linalg import solve\n",
    "import autograd.scipy.stats.multivariate_normal as mvn\n",
    "from autograd import value_and_grad\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_gp_funs(cov_func, num_cov_params):\n",
    "    \"\"\"Functions that perform Gaussian process regression.\n",
    "       cov_func has signature (cov_params, x, x')\"\"\"\n",
    "    \n",
    "    def unpack_kernel_params(params):\n",
    "        mean        = params[0]\n",
    "        cov_params  = params[2:]\n",
    "        noise_scale = np.exp(params[1]) + 0.0001\n",
    "        return mean, cov_params, noise_scale\n",
    "    \n",
    "    def predict(params, x, y, xstar):\n",
    "        \"\"\"Returns the predictive mean and covariance at locations xstar,\n",
    "           of the latent function value f (without observation noise).\"\"\"\n",
    "        mean, cov_params, noise_scale = unpack_kernel_params(params)\n",
    "        # Calculate covariances\n",
    "        # Calculate predictive mean\n",
    "        # Calculate predictive covariance\n",
    "        return pred_mean, pred_cov\n",
    "    \n",
    "    def log_marginal_likelihood(params, x, y):\n",
    "        mean, cov_params, noise_scale = unpack_kernel_params(params)\n",
    "        # Calculate *observation* covariance\n",
    "        # Enumerate 'prior' mean\n",
    "        return mvn.logpdf(y, prior_mean, cov_y_y)\n",
    "    \n",
    "    return num_cov_params + 2, predict, log_marginal_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a covariance function.\n",
    "def rbf_covariance(kernel_params, x, xp):\n",
    "    # params of: output scale, lengthscale (need to constrain to be positive!)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_toy_dataset(D=1, n_data=50, noise_std=0.2):\n",
    "    rs = npr.RandomState(0)\n",
    "    inputs  = np.concatenate([np.linspace(0, 4, num=n_data/2),\n",
    "                              np.linspace(6, 8, num=n_data/2)])\n",
    "    targets = (np.cos(inputs/4) + np.sin(inputs) + rs.randn(n_data) * noise_std) / 2.0\n",
    "    inputs = (inputs - 4.0) / 2.0\n",
    "    inputs  = inputs.reshape((len(inputs), D))\n",
    "    return inputs, targets\n",
    "\n",
    "D = 1\n",
    "n_data = 50\n",
    "noise_std=0.2\n",
    "X, y = build_toy_dataset(D=D, n_data=n_data, noise_std=noise_std)\n",
    "\n",
    "plt.plot(X,y,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPOILER ALERT ##\n",
    "# Code below is super useful, but does all the rest of the work for you!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Use this nifty code to optimize\n",
    "# Build model and objective function.\n",
    "num_params, predict, log_marginal_likelihood = make_gp_funs(rbf_covariance, num_cov_params=D + 1)\n",
    "objective = lambda params: -log_marginal_likelihood(params, X, y)\n",
    "# Initialize covariance parameters\n",
    "rs = npr.RandomState(0)\n",
    "init_params = 0.1 * rs.randn(num_params)\n",
    "# Optimize using conjugate gradients\n",
    "opt_params = minimize(value_and_grad(objective), init_params, jac=True, method='CG')\n",
    "params = opt_params.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use this nifty code to plot\n",
    "# Show posterior marginals.\n",
    "plot_xs = np.reshape(np.linspace(-7, 7, 300), (300,1))\n",
    "pred_mean, pred_cov = predict(params, X, y, plot_xs)\n",
    "marg_std = np.sqrt(np.diag(pred_cov))\n",
    "plt.plot(plot_xs, pred_mean, 'b')\n",
    "plt.fill(np.concatenate([plot_xs, plot_xs[::-1]]),\n",
    "        np.concatenate([pred_mean - 1.96 * marg_std,\n",
    "                       (pred_mean + 1.96 * marg_std)[::-1]]),\n",
    "        alpha=.15, fc='Blue', ec='None')\n",
    "plt.plot(X,y,'.')\n",
    "\n",
    "# Show samples from posterior.\n",
    "rs = npr.RandomState(0)\n",
    "sampled_funcs = rs.multivariate_normal(pred_mean, pred_cov, size=10)\n",
    "plot.plot(plot_xs, sampled_funcs.T)\n",
    "\n",
    "plt.plot(X, y, 'kx')\n",
    "plt.set_ylim([-1.5, 1.5])\n",
    "plt.set_xticks([])\n",
    "plt.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
